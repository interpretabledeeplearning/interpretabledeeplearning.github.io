
---
---

@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  pages={80--89},
  year={2018},
  organization={IEEE},
  arxiv={https://arxiv.org/abs/1806.00069}
}

@inproceedings{goebel2018explainable,
  title={Explainable AI: the new 42?},
  author={Goebel, Randy and Chander, Ajay and Holzinger, Katharina and Lecue, Freddy and Akata, Zeynep and Stumpf, Simone and Kieseberg, Peter and Holzinger, Andreas},
  booktitle={International cross-domain conference for machine learning and knowledge extraction},
  pages={295--303},
  year={2018},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-319-99740-7_21}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London},
  html={https://www.nature.com/articles/s42256-019-0048-x}
}

@article{arrieta2020explainable,
  title={Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information fusion},
  volume={58},
  pages={82--115},
  year={2020},
  publisher={Elsevier},
  arxiv={https://arxiv.org/abs/1910.10045}
}

@article{confalonieri2021historical,
  title={A historical perspective of explainable artificial intelligence},
  author={Confalonieri, Roberto and Coba, Ludovik and Wagner, Benedikt and Besold, Tarek R},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={11},
  number={1},
  pages={e1391},
  year={2021},
  publisher={Wiley Online Library},
  html={https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1391}
}

@article{vilone2021notions,
  title={Notions of explainability and evaluation approaches for explainable artificial intelligence},
  author={Vilone, Giulia and Longo, Luca},
  journal={Information Fusion},
  volume={76},
  pages={89--106},
  year={2021},
  publisher={Elsevier},
  html={https://www.sciencedirect.com/science/article/pii/S1566253521001093}
}

@inproceedings{freiesleben2023dear,
  title={Dear XAI community, we need to talk! Fundamental misconceptions in current XAI research},
  author={Freiesleben, Timo and K{\"o}nig, Gunnar},
  booktitle={World Conference on Explainable Artificial Intelligence},
  pages={48--65},
  year={2023},
  organization={Springer},
  arxiv={https://arxiv.org/abs/2306.04292}
}

@article{krishnadisagreement,
  title={The Disagreement Problem in Explainable Machine Learning: A Practitionerâ€™s Perspective},
  author={Krishna, Satyapriya and Han, Tessa and Gu, Alex and Wu, Steven and Jabbari, Shahin and Lakkaraju, Himabindu},
  journal={Transactions on Machine Learning Research},
  year={2022},
  arxiv={https://arxiv.org/abs/2202.01602}
}

@article{dombrowski2019explanations,
  title={Explanations can be manipulated and geometry is to blame},
  author={Dombrowski, Ann-Kathrin and Alber, Maximillian and Anders, Christopher and Ackermann, Marcel and M{\"u}ller, Klaus-Robert and Kessel, Pan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019},
  arxiv={https://arxiv.org/abs/1906.07983}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  arxiv={https://arxiv.org/abs/1810.03292}
}

@inproceedings{ghorbani2019interpretation,
  title={Interpretation of neural networks is fragile},
  author={Ghorbani, Amirata and Abid, Abubakar and Zou, James},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={3681--3688},
  year={2019},
  arxiv={https://arxiv.org/abs/1710.10547}
}

@inproceedings{bertrand2022cognitive,
  title={How cognitive biases affect XAI-assisted decision-making: A systematic review},
  author={Bertrand, Astrid and Belloum, Rafik and Eagan, James R and Maxwell, Winston},
  booktitle={Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={78--91},
  year={2022},
  html={https://dl.acm.org/doi/10.1145/3514094.3534164}
}

@article{barbiero2025foundations,
  title={Foundations of Interpretable Models},
  author={Barbiero, Pietro and Espinosa Zarlenga, Mateo and Termine, Alberto and Jamnik, Mateja and Marra, Giuseppe},
  journal={arXiv preprint arXiv:2508.00545},
  year={2025},
  arxiv={https://arxiv.org/abs/2508.00545}
}