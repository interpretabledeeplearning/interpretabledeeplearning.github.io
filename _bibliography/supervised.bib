
---
---
@inproceedings{bau2017network,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017},
  pdf={https://openaccess.thecvf.com/content_cvpr_2017/papers/Bau_Network_Dissection_Quantifying_CVPR_2017_paper.pdf}
}

@inproceedings{fong2018net2vec,
  title={Net2vec: Quantifying and explaining how concepts are encoded by filters in deep neural networks},
  author={Fong, Ruth and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8730--8738},
  year={2018},
  pdf={https://openaccess.thecvf.com/content_cvpr_2018/papers/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.pdf}
}

@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCAV)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR},
  pdf={https://proceedings.mlr.press/v80/kim18d/kim18d.pdf}
}

@article{crabbe2022concept,
  title={Concept activation regions: A generalized framework for concept-based explanations},
  author={Crabb{\'e}, Jonathan and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2590--2607},
  year={2022},
  arxiv={https://arxiv.org/abs/2209.11222}
}

@article{bai2022concept,
  title={Concept Gradient: Concept-based Interpretation Without Linear Assumption},
  author={Bai, Andrew and Yeh, Chih-Kuan and Ravikumar, Pradeep and Lin, Neil YC and Hsieh, Cho-Jui},
  journal={ICLR},
  year={2023},
  pdf={https://openreview.net/pdf?id=_01dDd3f78}
}












@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR},
  html={https://proceedings.mlr.press/v119/koh20a.html}
}

@article{zarlenga2023learning,
  title={Learning to Receive Help: Intervention-Aware Concept Embedding Models},
  author={Espinosa Zarlenga, Mateo and Collins, Katherine M and Dvijotham, Krishnamurthy and Weller, Adrian and Shams, Zohreh and Jamnik, Mateja},
  journal={NeurIPS},
  year={2023},
  arxiv={https://arxiv.org/abs/2309.16928}
}

@article{marconato2022glancenets,
  title={Glancenets: Interpretable, leak-proof concept-based models},
  author={Marconato, Emanuele and Passerini, Andrea and Teso, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21212--21227},
  year={2022},
  arxiv={https://arxiv.org/abs/2205.15612}
}

@article{oikarinen2023label,
  title={Label-Free Concept Bottleneck Models},
  author={Oikarinen, Tuomas and Das, Subhro and Nguyen, Lam M and Weng, Tsui-Wei},
  journal={ICLR},
  year={2023},
  arxiv={https://arxiv.org/abs/2304.06129}
}

@article{espinosa2022concept,
  title={Concept embedding models: Beyond the accuracy-explainability trade-off},
  author={Espinosa Zarlenga, Mateo and Barbiero, Pietro and Ciravegna, Gabriele and Marra, Giuseppe and Giannini, Francesco and Diligenti, Michelangelo and Shams, Zohreh and Precioso, Frederic and Melacci, Stefano and Weller, Adrian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21400--21413},
  year={2022},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2022/file/867c06823281e506e8059f5c13a57f75-Paper-Conference.pdf}
}

@article{yuksekgonul2022post,
  title={Post-hoc concept bottleneck models},
  author={Yuksekgonul, Mert and Wang, Maggie and Zou, James},
  journal={ICLR},
  year={2023},
  arxiv={https://arxiv.org/abs/2205.15480}
}


@article{chen2020concept,
  title={Concept whitening for interpretable image recognition},
  author={Chen, Zhi and Bei, Yijie and Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={2},
  number={12},
  pages={772--782},
  year={2020},
  publisher={Nature Publishing Group UK London},
  html={https://www.nature.com/articles/s42256-020-00265-z}
}

@article{kim2023probabilistic,
  title={Probabilistic Concept Bottleneck Models},
  author={Kim, Eunji and Jung, Dahuin and Park, Sangha and Kim, Siwon and Yoon, Sungroh},
  journal={ICML},
  year={2023},
  arxiv={https://arxiv.org/abs/2306.01574}
}

@article{kim2023probabilistic,
  title={Probabilistic Concept Bottleneck Models},
  author={Kim, Eunji and Jung, Dahuin and Park, Sangha and Kim, Siwon and Yoon, Sungroh},
  journal={ICML},
  year={2023},
  arxiv={https://arxiv.org/abs/2306.01574}
}

@article{olah2017feature,
  title={Feature visualization},
  author={Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  journal={Distill},
  volume={2},
  number={11},
  pages={e7},
  year={2017},
  html={https://distill.pub/2017/feature-visualization/}
}

@article{margeloiu2021concept,
  title={Do concept bottleneck models learn as intended?},
  author={Margeloiu, Andrei and Ashman, Matthew and Bhatt, Umang and Chen, Yanzhi and Jamnik, Mateja and Weller, Adrian},
  journal={ICLR Workshop on Responsible AI},
  year={2021},
  arxiv={https://arxiv.org/abs/2105.04289}
}

@article{mahinpei2021promises,
  title={Promises and pitfalls of black-box concept learning models},
  author={Mahinpei, Anita and Clark, Justin and Lage, Isaac and Doshi-Velez, Finale and Pan, Weiwei},
  journal={ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI},
  year={2021},
  arxiv={https://arxiv.org/abs/2106.13314}
}

@article{raman2024concept,
  title={Do Concept Bottleneck Models Respect Localities?},
  author={Raman, Naveen and Zarlenga, Mateo Espinosa and Heo, Juyeon and Jamnik, Mateja},
  journal={NeurIPS Workshop on XAI in Action},
  year={2024},
  arxiv={https://arxiv.org/abs/2401.01259}
}

@inproceedings{raman2024understanding,
  title={Understanding inter-concept relationships in concept-based models},
  author={Raman, Naveen and Espinosa Zarlenga, Mateo and Jamnik, Mateja},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={42009--42025},
  year={2024},
  arxiv={https://arxiv.org/abs/2405.18217}
}

@inproceedings{sinha2023understanding,
  title={Understanding and enhancing robustness of concept-based models},
  author={Sinha, Sanchit and Huai, Mengdi and Sun, Jianhui and Zhang, Aidong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={12},
  pages={15127--15135},
  year={2023},
  arxiv={https://arxiv.org/abs/2211.16080}
}


@inproceedings{heidemann2023concept,
  title={Concept correlation and its effects on concept-based models},
  author={Heidemann, Lena and Monnet, Maureen and Roscher, Karsten},
  booktitle={Proceedings of the ieee/cvf winter conference on applications of computer vision},
  pages={4780--4788},
  year={2023},
  pdf={https://openaccess.thecvf.com/content/WACV2023/papers/Heidemann_Concept_Correlation_and_Its_Effects_on_Concept-Based_Models_WACV_2023_paper.pdf}
}

@inproceedings{zarlenga2023towards,
  title={Towards robust metrics for concept representation evaluation},
  author={Zarlenga, Mateo Espinosa and Barbiero, Pietro and Shams, Zohreh and Kazhdan, Dmitry and Bhatt, Umang and Weller, Adrian and Jamnik, Mateja},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={10},
  pages={11791--11799},
  year={2023},
  arxiv={https://arxiv.org/abs/2301.10367}
}

@inproceedings{bortolottineuro,
  title={A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts},
  author={Bortolotti, Samuele and Marconato, Emanuele and Carraro, Tommaso and Morettin, Paolo and van Krieken, Emile and Vergari, Antonio and Teso, Stefano and Passerini, Andrea},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024},
  arxiv={https://arxiv.org/abs/2406.10368}
}

@article{marconato2023interpretability,
  title={Interpretability is in the mind of the beholder: A causal framework for human-interpretable representation learning},
  author={Marconato, Emanuele and Passerini, Andrea and Teso, Stefano},
  journal={Entropy},
  volume={25},
  number={12},
  pages={1574},
  year={2023},
  publisher={MDPI},
  arxiv={https://arxiv.org/abs/2309.07742}
}


@article{havasi2022addressing,
  title={Addressing leakage in concept bottleneck models},
  author={Havasi, Marton and Parbhoo, Sonali and Doshi-Velez, Finale},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23386--23397},
  year={2022},
  html={https://proceedings.neurips.cc/paper_files/paper/2022/hash/944ecf65a46feb578a43abfd5cddd960-Abstract-Conference.html}
}

@inproceedings{xuenergy,
  title={Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations},
  author={Xu, Xinyue and Qin, Yi and Mi, Lu and Wang, Hao and Li, Xiaomeng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  arxiv={https://arxiv.org/abs/2401.14142}
}

@inproceedings{ye2024concept,
  title={Concept-Based Interpretable Reinforcement Learning with Limited to No Human Labels},
  author={Ye, Zhuorui and Milani, Stephanie and Fang, Fei and Gordon, Geoffrey J},
  booktitle={Workshop on Interpretable Policies in Reinforcement Learning at RLC-2024},
  year={2024},
  arxiv={https://arxiv.org/abs/2407.15786}
}

@article{kazhdan2020meme,
  title={MEME: generating RNN model explanations via model extraction},
  author={Kazhdan, Dmitry and Dimanov, Botty and Jamnik, Mateja and Li{\`o}, Pietro},
  journal={NeurIPS HAMLETS Workshop},
  year={2020},
  arxiv={https://arxiv.org/abs/2012.06954}
}

@inproceedings{shin2023closer,
  title={A closer look at the intervention procedure of concept bottleneck models},
  author={Shin, Sungbin and Jo, Yohan and Ahn, Sungsoo and Lee, Namhoon},
  booktitle={International Conference on Machine Learning},
  pages={31504--31520},
  year={2023},
  organization={PMLR},
  arxiv={https://arxiv.org/abs/2302.14260}
}

@inproceedings{chauhan2023interactive,
  title={Interactive concept bottleneck models},
  author={Chauhan, Kushal and Tiwari, Rishabh and Freyberg, Jan and Shenoy, Pradeep and Dvijotham, Krishnamurthy},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={5},
  pages={5948--5955},
  year={2023},
  arxiv={https://arxiv.org/abs/2212.07430}
}

@inproceedings{steinmannlearning,
  title={Learning to Intervene on Concept Bottlenecks},
  author={Steinmann, David and Stammer, Wolfgang and Friedrich, Felix and Kersting, Kristian},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  arxiv={https://arxiv.org/abs/2308.13453}
}

@inproceedings{vandenhirtzstochastic,
  title={Stochastic Concept Bottleneck Models},
  author={Vandenhirtz, Moritz and Laguna, Sonia and Marcinkevi{\v{c}}s, Ri{\v{c}}ards and Vogt, Julia E},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024},
  arxiv={https://arxiv.org/abs/2406.19272}
}

@inproceedings{laguna2024beyond,
  title={Beyond concept bottleneck models: How to make black boxes intervenable?},
  author={Laguna Cillero, Sonia and Marcinkevi{\v{c}}s, Ri{\v{c}}ards and Vandenhirtz, Moritz and Vogt, Julia E},
  booktitle={38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024), Vancouver, Canada, December 10-15, 2024},
  year={2024},
  arxiv={https://arxiv.org/abs/2401.13544}
}
@inproceedings{sheth2022learning,
  title={Learning from uncertain concepts via test time interventions},
  author={Sheth, Ivaxi and Rahman, Aamer Abdul and Sevyeri, Laya Rafiee and Havaei, Mohammad and Kahou, Samira Ebrahimi},
  booktitle={Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS 2022},
  year={2022},
  html={https://openreview.net/forum?id=WVe3vok8Cc3}
}