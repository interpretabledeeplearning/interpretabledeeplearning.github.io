---
layout: home
title: Home
home_title: Foundations of Interpretable Deep Learning
subtitle:
nav_title: Home
permalink: /
description:
---

<div style="margin: auto; text-align: center;">
  Tutorial held in conjunction with <a href="https://aaai.org/conference/aaai/aaai-26/">AAAI 2026</a><br>

  Singapore EXPO (Room TBC), Singapore<br>

  January 20th or 21st (exact date and time TBC)<br>

</div>

## Introduction

As notoriously opaque deep neural networks (DNNs) become commonplace in powerful Artificial Intelligence (AI) systems, Interpretable Deep Learning (IDL) has emerged as a promising direction for designing interpretable-by-construction neural architectures. At their core, IDL models learn a latent space where some of their representations are aligned with high-level units of information, or concepts, that domain experts are familiar with (e.g., "stripped texture",  "round object", etc.). By introducing inductive biases that encourage predictions to be made based on these interpretable representations, IDL models enable the construction of expressive yet highly transparent architectures that can be vetted, analysed, and intervened on.

This tutorial aims to capitalise on the surge of interest in IDL by exposing AI researchers and engineers to the core foundations necessary to understand the general principles behind existing IDL models. By doing so, we aim to equip attendees with the knowledge necessary to comprehend the current state of this extensive body of literature, enabling them to build upon it for their research. Specifically, this tutorial will provide an overview of (1) core interpretability principles, (2) seminal works in the field, and (3) recent directions in IDL. Our tutorial will include hands-on demonstrations throughout our session and will conclude with a discussion of the key open questions in the field.

#### Required Background

Our material will assume a basic knowledge of ML (e.g., foundations of supervised learning, experimental design, basic probabilistic modelling, etc.), with particular emphasis on a solid Deep Learning foundation (e.g., tensor calculus, neural networks, backpropagation, etc.). Concepts that may require mathematical tools/expertise beyond those one would expect to be shared among the AAAI community will be (re)introduced in our tutorial.

All relevant material used and discussed during the tutorial, **including a recording of the tutorial**, will be made available [here](/tutorial).

#### Previous Tutorial Iterations

A related but distinct previous iteration of this tutorial was ran at AAAI 2025 under the name of ["Concept-based Interpretable Deep Learning"](https://conceptlearning.github.io/tutorial/). A more closely related iteration of the present tutorial was ran
as a short talk at [**Neuro-Symbolic AI Summer School 2025**](https://lu.ma/pqzv80yd).

Please see [here](https://conceptlearning.github.io/tutorial/) for further details on these previous tutorials, including slides and materials.


## Important Details


- **Date**: This tutorial will be held on either on January 20th or January 21st, 2026 (exact date and time TBD).
- **Conference**: The Fortieth Annual [AAAI Conference on Artificial Intelligence](https://aaai.org/conference/aaai/aaai-26/).
- **Location**: Singapore EXPO (Room TBC), Singapore.
- **Modality**: In-person event with the option to join online via Underline (requires AAAI tutorial registration).


## Presenters
  <div class="row projects pt-1 pb-1" style="justify-content: center;">
      <div class="col-sm-4">
          {% include people.html name="Mateo Espinosa Zarlenga" affiliation="University of Cambridge, UK" url="https://mateoespinosa.github.io/" img="/assets/img/people/mateo.jpg" %}
      </div>
      <div class="col-sm-4">
        {% include people.html name="Pietro Barbiero" affiliation="IBM Research, Switzerland" url="https://www.pietrobarbiero.eu/" img="/assets/img/people/pietro.jpeg" %}
      </div>
  </div>


## Contact

For any questions, please do not hesitate to contact Mateo at
[me466@cam.ac.uk](mailto:me466@cam.ac.uk).
